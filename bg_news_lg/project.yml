title: "Bulgarian Part-of-speech Tagging & Dependency Parsing using Universal Dependencies"


# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  config: "config"
  lang: "bg"
  treebank: "UD_Bulgarian-BTB"
  train_name: "bg_btb-ud-train"
  dev_name: "bg_btb-ud-dev"
  test_name: "bg_btb-ud-test"
  package_name: "news_lg"
  package_version: "3.5.4"
  gpu: -1

spacy_version: ">=3.3.0,<4.0.0"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "corpus", "training", "metrics", "configs", "packages", "vectors"]

assets:
  - dest: "assets/${vars.treebank}"
    git:
      repo: "https://github.com/UniversalDependencies/${vars.treebank}"
      branch: "master"
      path: ""

workflows:
  all:
    - preprocess
    - init-floret-vectors
    - train
    - evaluate
    - train-ner
    - evaluate-ner
    - assemble_package

commands:
  - name: preprocess
    help: "Convert the data to spaCy's format"
    script:
      - "mkdir -p corpus/${vars.treebank}"
      - >-
        python -m spacy convert
        assets/${vars.treebank}/${vars.train_name}.conllu 
        corpus/${vars.treebank}/ 
        --converter conllu 
        --n-sents 10 
        --merge-subtokens
      - >-
        python -m spacy convert 
        assets/${vars.treebank}/${vars.dev_name}.conllu 
        corpus/${vars.treebank}/ 
        --converter conllu 
        --n-sents 10 
        --merge-subtokens
      - >-
        python -m spacy convert 
        assets/${vars.treebank}/${vars.test_name}.conllu
        corpus/${vars.treebank}/
        --converter conllu 
        --n-sents 10 
        --merge-subtokens
      - "mv corpus/${vars.treebank}/${vars.train_name}.spacy corpus/${vars.treebank}/train.spacy"
      - "mv corpus/${vars.treebank}/${vars.dev_name}.spacy corpus/${vars.treebank}/dev.spacy"
      - "mv corpus/${vars.treebank}/${vars.test_name}.spacy corpus/${vars.treebank}/test.spacy"
    deps:
      - "assets/${vars.treebank}/${vars.train_name}.conllu"
      - "assets/${vars.treebank}/${vars.dev_name}.conllu"
      - "assets/${vars.treebank}/${vars.test_name}.conllu"
    outputs:
      - "corpus/${vars.treebank}/train.spacy"
      - "corpus/${vars.treebank}/dev.spacy"
      - "corpus/${vars.treebank}/test.spacy"
      
  - name: "init-floret-vectors"
    help: "Create a floret vectors model"
    script:
      - "python -m spacy init vectors ${vars.lang} ../bg_floret_vectors_lg/${vars.lang}.floret ./vectors/${vars.lang}_floret_model --mode floret"
    deps:
      - "../bg_floret_vectors_lg/${vars.lang}.floret"
    outputs:
      - "./vectors/${vars.lang}_floret_model"
  
  - name: "train"
    help: "Train the model with floret vectors"
    script:
      - "python -m spacy train configs/${vars.config}.cfg --output training/${vars.treebank}-floret/ --gpu-id ${vars.gpu} --paths.train corpus/${vars.treebank}/train.spacy --paths.dev corpus/${vars.treebank}/dev.spacy  --code ./language_components/functions.py  --initialize.vectors vectors/${vars.lang}_floret_model --nlp.lang=${vars.lang}"
    deps:
      - "configs/${vars.config}.cfg"
      - "corpus/${vars.treebank}/train.spacy"
      - "corpus/${vars.treebank}/dev.spacy"
      - "vectors/${vars.lang}_floret_model"
    outputs:
      - "training/${vars.treebank}-floret/model-best"  

  - name: evaluate
    help: "Evaluate on the test data and save the metrics"
    script:
      - "python -m spacy evaluate ./training/${vars.treebank}-floret/model-best ./corpus/${vars.treebank}/test.spacy --output ./metrics/${vars.treebank}-floret.json --gpu-id ${vars.gpu}"
    deps:
      - "training/${vars.treebank}-floret/model-best"
      - "corpus/${vars.treebank}/test.spacy"
    outputs:
      - "metrics/${vars.treebank}-floret.json"

  - name: "train-ner"
    help: "Train the NER model with vectors"
    script:
      - "python -m spacy train configs/config_ner.cfg --output training/ner_lg/ --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy --gpu-id ${vars.gpu} --initialize.vectors ${vars.vectors_model} --components.tok2vec.model.embed.include_static_vectors true"
    deps:
      - "configs/config_ner.cfg"
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
    outputs:
      - "training/ner_lg/model-best"
  
  - name: "evaluate-ner"
    help: "Evaluate the model and export metrics"
    script:
     - "python -m spacy evaluate training/ner_lg/model-best corpus/dev.spacy --output training/ner_lg/metrics.json"
    deps:
     - "corpus/dev.spacy"
     - "training/ner_lg/model-best"
    outputs:
     - "training/ner_lg/metrics.json"
  
  - name: "assemble_package"
    help: "Assemble the bg_ner and bg_tagger_parser models and package them as a spaCy pipeline"
    script:
      - >-
        python -m spacy assemble configs/assemble.cfg training/${vars.package_name}/model-best
        --paths.parser_model training/${vars.package_name}/model-best
        --paths.ner_model training/ner_lg/model-best
        --verbose
      - >-
        python -m spacy package training/${vars.package_name}/model-best packages/
        --build wheel
        --name ${vars.package_name}
        --version ${vars.package_version}
        --meta-path meta.json
        --force
    deps:
      - training/${vars.package_name}/model-best
      - training/ner_lg/model-best
    outputs:
      - packages/bg_news_lg_${vars.package_version}

  - name: clean
    help: "Remove intermediate files"
    script:
      - "rm -rf training/*"
      - "rm -rf metrics/*"
      - "rm -rf corpus/*"